---
coverImageWidth: "1200"
coverImageHeight: "700"
datetime: 2025-03-10T14:37:30Z
tags:
  - MicroK8s
  - NextJS
  - Tailwind CSS
  - Blog
author: Woulf
type: article
coverImage: https://dev-to-uploads.s3.amazonaws.com/uploads/articles/igr6uvksvy20ot1wqof3.png
coverImageAlt: GitOps K8s scheme
title: Article 4 - DÃ©ploiement Kubernetes avec GitOps
excerpt:
  DÃ©ploiement de mon infrastructure Kubernetes versionnÃ©e avec GitOps, avec application automatisÃ©e via une pipeline dÃ©diÃ©e et exposition publique de mon portfolio.
slug: automatisation-deploiement-portfolio4
featured: false
category: DevOps & DÃ©veloppement
language: French
---

AprÃ¨s avoir mis en place le build et le push de mon image Docker, il est temps dâ€™aller plus loin : **versionner et automatiser le dÃ©ploiement de mon infrastructure Kubernetes**.

---

## SÃ©paration des responsabilitÃ©s : code vs infra

Pour garder une architecture propre et maintenir une logique GitOps, jâ€™ai sÃ©parÃ© lâ€™infrastructure du code applicatif dans deux dÃ©pÃ´ts Git diffÃ©rents :

- [`Wooulf/forkfolio`](https://github.com/Wooulf/forkfolio) : contient le code source de mon site (Next.js), le `Dockerfile` et une pipeline CI pour builder + dÃ©ployer lâ€™image Docker.
- [`Wooulf/infra-k8s-terraform`](https://github.com/Wooulf/infra-k8s-terraform) : contient **tous les fichiers de configuration Kubernetes** (`deployment.yaml`, `service.yaml`, etc.), et une **autre pipeline CI/CD** dÃ©diÃ©e Ã  leur application sur le cluster.

ğŸ¯ Ce dÃ©coupage permet de dÃ©coupler le code applicatif de l'infrastructure, ce qui facilite la maintenance, les revues de code ciblÃ©es, et lâ€™Ã©volution des deux parties de maniÃ¨re indÃ©pendante.

---

## DÃ©ploiement de l'application sur MicroK8s

Pour que mon application tourne sur le cluster et soit exposÃ©e proprement au public, jâ€™ai mis en place les Ã©lÃ©ments suivants :

- Un **Deployment** : qui gÃ¨re le cycle de vie du pod (mises Ã  jour, rÃ©silienceâ€¦)
- Un **Service ClusterIP** : pour stabiliser la communication interne vers le pod
- Un **Ingress** : pour router les requÃªtes HTTP externes vers la bonne application
- Un **Service NodePort** : pour exposer lâ€™Ingress Controller au monde extÃ©rieur

---

## Une requÃªte, un chemin

L'ensemble de ces composants permet de faire transiter une requÃªte HTTP entrante Ã  travers le cluster, comme ceci :

> ğŸŒ `Client` â†’ `VPS` (port 80) â†’ `NodePort` â†’ `Ingress` â†’ `ClusterIP` â†’ `Pod`

Voici un schÃ©ma clair et visuel du fonctionnement :

![SchÃ©ma de routage Kubernetes vers mon app portfolio](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/abuijcwf91jng0eyr5mf.jpg)

---

## Fichiers de dÃ©finition Kubernetes

Voici les fichiers versionnÃ©s dans le repo dâ€™infra :

### ğŸ§± Deployment

GÃ¨re le dÃ©ploiement du conteneur, les mises Ã  jour, la redondance.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: portfolio
spec:
  replicas: 1
  selector:
    matchLabels:
      app: portfolio
  template:
    metadata:
      labels:
        app: portfolio
    spec:
      containers:
        - name: portfolio
          image: woulf/portfolio:latest
          ports:
            - containerPort: 3000
```

---

### ğŸŒ Service ClusterIP

Expose le pod Ã  lâ€™intÃ©rieur du cluster via une IP stable.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: portfolio
spec:
  selector:
    app: portfolio
  ports:
    - port: 80
      targetPort: 3000
```

---

### ğŸŒ Ingress

Fait le lien entre un nom de domaine (`woulf.fr`) et le bon service interne.

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: woulf-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
    - host: woulf.fr
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: portfolio
                port:
                  number: 3000
  ingressClassName: nginx
```

---

### ğŸ›£ï¸ Ingress Controller (NodePort)

Expose le contrÃ´leur nginx de lâ€™Ingress sur un port externe du VPS.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-ingress-microk8s-controller
  namespace: ingress
spec:
  type: NodePort
  externalIPs:
    - 185.216.27.229
  selector:
    name: nginx-ingress-microk8s
  ports:
    - port: 80
      targetPort: 80
      nodePort: 32180
```

---

## Pipeline GitHub Actions dans le repo infra

Une fois les fichiers versionnÃ©s, je les applique automatiquement sur mon cluster grÃ¢ce Ã  une **deuxiÃ¨me pipeline CI/CD** dans le dÃ©pÃ´t `infra-k8s-terraform`.

Elle sâ€™exÃ©cute dÃ¨s quâ€™un fichier est modifiÃ© dans le dossier `k8s/` :

```yaml
on:
  push:
    paths:
      - 'k8s/**'

jobs:
  apply_k8s_configs:
    steps:
      - uses: actions/checkout@v4
      - uses: azure/k8s-set-context@v3
        with:
          kubeconfig: ${{ secrets.KUBECONFIG }}
      - run: kubectl apply -f k8s/
      - run: kubectl get all
```

âœ… RÃ©sultat : Ã  chaque commit de config, **le cluster se synchronise automatiquement**.

---

## Et la suite ?

Je pourrais aller encore plus loin avec un **outil GitOps complet** comme **ArgoCD** ou **Flux**. Ces outils se chargeraient de **surveiller le dÃ©pÃ´t Git en continu** et de mettre Ã  jour le cluster **sans passer par une pipeline manuelle**.

Mais pour un MVP, cette solution en deux pipelines fait dÃ©jÃ  le job ğŸ‘Œ

---

ğŸ’¡ Dans le prochain article, je parlerai de la **gestion des secrets**, du futur passage en **HTTPS**, des idÃ©es de **monitoring**, et des prochaines Ã©volutions possibles de mon infrastructure.
